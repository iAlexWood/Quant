# Kronos：金融市场语言的基础模型

于石、付宗良、陈硕、赵博涵、徐伟、张长水、李健
清华大学自动化系跨学科信息科学研究所
{shi-y23, fzl22, zhaobh23}@mails.tsinghua.edu.cn, ChenSh2003@outlook.com, weixu@tsinghua.edu.cn,zcs@mail.tsinghua.edu.cn, lapordge@gmail.com

## 摘要

以大型语言模型（LLM）为代表的大规模预训练范式的成功，激发了时间序列基础模型（TSFM）的发展。然而，它们在金融 K 线（candlestick）数据上的应用仍然有限，表现常常不及非预训练的架构。此外，现有的 TSFM 往往忽视了波动率预测和合成数据生成等关键的下游任务。为了解决这些局限性，我们提出了 Kronos，一个专为金融 K 线建模量身定制的、统一且可扩展的预训练框架。Kronos 引入了一个专门的分词器（tokenizer），将连续的市场信息离散化为词元（token）序列，同时保留了价格动态和交易活动模式。我们在一个庞大的、跨市场的语料库上使用自回归目标对 Kronos 进行了预训练，该语料库包含来自全球 45 个交易所的超过 120 亿条 K 线记录，使其能够学习到精细的时间和跨资产表征。Kronos 在零样本（zero-shot）设置下，在一系列多样化的金融任务中表现出色。在基准数据集上，Kronos 在价格序列预测上的 RankIC 相较于领先的 TSFM 提升了 93%，相较于最佳的非预训练基线提升了 87%。它还在波动率预测中实现了 9% 的平均绝对误差（MAE）降低，并在合成 K 线序列的生成保真度上提升了 22%。这些结果确立了 Kronos 作为一个强大的、多功能的基础模型，适用于端到端的金融时间序列分析。我们的预训练模型已公开发布于 [https://github.com/shiyu-coder/Kronos](https://github.com/shiyu-coder/Kronos)。

---

## 1 引言

基础模型（FMs）的出现引发了人工智能领域的范式转变，重塑了表征学习和下游任务适应的方法论。大型语言模型（LLMs）在自然语言处理上的成功（Brown et al. 2020; Achiam et al. 2023）以及计算机视觉领域的并行突破（Radford et al. 2021; Kirillov et al. 2023）都例证了这一转变。

受这些进展的启发，FM 范式最近已扩展到时序数据，催生了时间序列基础模型（TSFMs）（Garza, Challu, and Mergenthaler-Canseco 2023; Woo et al. 2024; Xiaoming et al. 2025）。其核心目标是构建预训练的、任务不可知（task-agnostic）的架构，作为多样化时间序列分析任务（从预测、异常检测到因果推断）的通用骨干，从而大幅减少在每个应用领域中设计定制模型的需求。

在这个不断扩展的研究领域中，金融市场因其固有的数据丰富性、高频观测以及复杂、非平稳的时间动态，而成为 TSFM 的一个关键且具有挑战性的应用领域。该领域的核心是 K 线序列，这是源自 K 线图的多变量时间序列，记录了固定时间间隔内的开盘价（Open）、最高价（High）、最低价（Low）和收盘价（Close），以及成交量（Volume）和成交额（Amount / Turnover）（OHLCVA）。这些序列构成了一种高度紧凑、信息密集的“语言”，市场参与者通过它来解读价格变动、波动率机制、流动性变化和集体情绪（Nison 2001）。因此，K 线数据构成了众多算法交易策略、投资组合优化方案和风险管理系统的基石。

![Refer to caption](https://arxiv.org/html/2508.02739v1/x1.png)

**图 1：Kronos 在多个量化金融任务上的综合表现。** 该图表将我们的 Kronos 模型（蓝色家族）与几类专业基线进行了基准比较。距离中心越远表示性能越优越。


然而，将通用 TSFM 应用于金融 K 线数据面临着重大挑战，这主要源于两个因素。首先，K 线序列表现出独特的统计特性，例如低信噪比、强非平稳性，以及 OHLCVA 属性之间错综复杂的高阶依赖关系（Zhang and Hua 2025; Baidya and Lee 2024），这些特性往往与通用 TSFM 的归纳偏置（inductive biases）不一致。其次，金融领域在很大程度上被主流 TSFM 研究所忽视；对于大多数现有的 TSFM 而言，金融序列在其预训练语料库中仅占极小部分（Das et al. 2024; Gao et al. 2024; Xiaoming et al. 2025），并且对量化金融至关重要的下游任务——跨越波动率估计、合成序列生成和风险管理——在很大程度上仍未得到解决。这些因素导致了一个重要的观察结果，我们在本工作中通过经验验证了这一点：通用 TSFM 在金融任务上的表现往往不及专门的、非预训练的模型（例如 iTransformer (Liu et al. 2023)），并且未能在更广泛的量化金融领域中实现泛化。

为了解决这些缺陷，我们引入了 Kronos，这是一个专为金融 K 线数据设计的、统一且可扩展的预训练框架。Kronos 采用一个专门的分词器将连续的、多变量的 K 线输入离散化为紧凑的词元序列，保留了关键的价格-成交量互动信息。然后，它在一个包含超过 120 亿条 K 线记录的、来自超过 45 个全球市场和 7 种时间粒度的、庞大且异构的语料库上进行自回归预训练。

我们通过在 一系列量化金融任务上的综合实验，验证了 Kronos 的有效性，其高层概括见图 1。在价格序列预测的核心任务上，Kronos 树立了新的业界顶尖（state-of-the-art）水平，其 RankIC 相较于领先的 TSFM 提升了 93%，相较于表现最佳的非预训练基线提升了 87%。此外，它通过在波动率预测中实现 9% 的平均绝对误差（MAE）降低，以及在合成 K 线生成中实现 22% 的生成保真度提升，展现了强大的多功能性。这些发现突显了我们方法的广泛有效性，并强调了 Kronos 作为解释金融市场复杂“语言”的强大基础模型的潜力。

我们的主要贡献可归纳如下：

-   我们为金融 K 线数据提出了一种新颖的建模框架，该框架学习层次化表征。它具有一个专门的分词器，可将每个多变量 K 线记录量化为结构化的、双组分（粗粒度和细粒度）词元，并辅以一个定制的自回归目标，该目标按顺序预测这些子词元。这种从粗到细（coarse-to-fine）的预测方案使 Kronos 能够显式地建模多尺度市场动态。
    
-   我们为一系列具有不同容量的 Kronos 模型进行了大规模预训练。这是在一个包含超过 120 亿条 K 线记录的、来自超过 45 个全球交易所的、庞大且多样化的金融语料库上进行的，这对于学习到支撑模型有效性的、鲁棒且可泛化的市场表征至关重要。
    
-   我们在一系列量化金融任务上进行了全面的实证评估。我们的结果表明，Kronos 在价格序列预测方面树立了新的 SOTA 水平，显著优于 TSFM 和专业基线。该模型在更广泛的量化任务（包括波动率预测和合成 K 线生成）上的强大表现进一步证明了其多功能性。
    

## 2 准备工作

令 $D$ 维向量  $\mathbf x_t \in \mathbb{R}^{D}$  表示在离散时间 $t$ 的 K 线观测值，包含 $D$ 个关键金融指标。在这项工作中，我们固定维度 $D=6$ ，以代表 OHLCVA 属性（开盘价、最高价、最低价、收盘价、成交量和成交额）。选择此输入的理由在附录 H (Q1) 中有详细说明。给定一个历史序列 $\mathbf {x_{1:T}} =(\mathbf {x_1},\mathbf {x_2},\ldots,\mathbf {x_T})$ ，我们的目标是预测接下来的 $H$ 个观测值 $\widehat{\mathbf{x}}\_{T+1:T+H}=(\widehat{\mathbf{x}}\_{T+1},\widehat{\mathbf{x}}\_{T+2},\ldots,\widehat{\mathbf{x}}\_{T+H})$ 。

Kronos 并不直接操作原始的连续输入，而是首先通过一个可学习的码本（codebook） $\mathcal{C}$ 将每个多变量观测值 $\mathbf{x}\_{t}$ 量化为一个离散的词元 $b\_{t}$ 。因此，原始序列 $\mathbf{x}\_{1:T}=(\mathbf{x}\_{1},\dots,\mathbf{x}\_{T})$ 被映射为 $\mathbf{b}\_{1:T}=(b\_{1},\dots,b\_{T})$ 。预测任务随后简化为一个自回归的词元序列建模问题：

```math
p(\mathbf{b}_{T+1:T+H} \mid \mathbf{b}_{1:T})= \prod_{h=1}^{H}p\left(b_{T+h}\mid\mathbf{b}_{1:T+h-1}\right)
```

这种离散的表述方式具有内在的可扩展性，并且能自然地扩展到其他可以被构建为生成式框架的任务，例如合成数据生成和波动率预测。

## 3 方法论

Kronos 将金融 K 线序列抽象为一种离散的语言，并通过一个如图 2 所示的两阶段框架来实现：(1) **K 线分词（Tokenization）** 和 (2) **自回归预训练（Autoregressive Pre-training）** 。

<img width="4748" height="2213" alt="Overview" src="https://github.com/user-attachments/assets/fa2ba616-f8f6-4b79-b683-f7868cee79d6" />


---

**图 2**：Kronos 的两阶段框架。 (1) **基于实例的 K 线分词**：一个基于 Transformer 的自动编码器，具有双重重构目标，将连续的 K 线数据量化为一个由层次化离散词元组成的词汇表，每个词元包含一个粗粒度子词元和一个细粒度子词元。(2) **自回归预训练**：一个仅解码器的 Transformer 被预训练来建模时间动态，通过在给定历史的条件下，按顺序预测下一时间步的层次化子词元。

---

在第一阶段，我们设计了一个专门的基于 Transformer 的分词器，通过一个可学习的码本，将连续的、多变量的 K 线序列量化为相应的离散词元序列。每个 K 线项（OHLCVA）被视为一个单独的实例，并被量化为一个离散词元。每个词元由一个粗粒度子词元和一个细粒度子词元组成。这一特性通过一种层次化重构损失（hierarchical reconstruction loss）来强制实现，该损失明确地迫使子词元建模不同层级的信息，从而创建了一个从粗到细的信息层次结构。

在第二阶段，一个自回归的、仅解码器（decoder-only）的 Transformer 在这些分词后的序列上进行预训练，使用标准的“下一词元预测”目标，在给定历史上下文的条件下，按顺序预测未来每个时间步的两个子词元层级。这种统一的“离散化-生成”范式使 Kronos 能够构建市场动态的高保真、层次化表征，为下游的量化分析提供了坚实的基础。

### K-line Tokenization

Kronos 的第一阶段是将一个连续的、$D$ 维 K 线序列 $\mathbf{x} = (\mathbf{x}\_{1}, \ldots, \mathbf{x}\_{T})$（其中 $\mathbf{x}\_{t}\in\mathbb{R}^{D}$ 编码了 OHLCVA 指标）转换为一个相应的离散词元序列。这是通过一个基于 Transformer 的自动编码器（图 3）实现的，该编码器由一个编码器 $E\_{\text{enc}}$、一个量化器 $Q$ 和一个解码器 $E\_{\text{dec}}$ 组成。

<img width="3128" height="2536" alt="Tokenizer" src="https://github.com/user-attachments/assets/9283385d-4d9d-4078-b4a5-20aa8f26882d" />


**图 3：K 线分词器（K-line Tokenizer）的架构。** 它采用了一个基于 Transformer 的自动编码器，带有一个二元球面量化（BSQ）层。

---

从生成模型中视频量化方法（Van Den Oord, Vinyals et al. 2017; Yu et al. 2023）中汲取灵感，我们调整了二元球面量化（Binary Spherical Quantization, BSQ）（Zhao, Xiong, and Krähenbühl 2024）—— 一种无查找量化（Look-up Free Quantization, LFQ）（Yu et al. 2023）的变体 —— 来完成此任务。我们在附录 H (Q2) 中讨论了这一选择的理由。BSQ 通过将连续的潜在向量 $\boldsymbol{\xi}\_t$ 投影到一组可学习的超平面上，将其量化为一个 $k$ 比特的二元编码 $b\_t \in \{-1,1\}^k$ 。

虽然大量的比特 $k$（例如 $k=20$）对于捕捉丰富的金融模式是可取的，但这会导致 $2^k$ 这样指数级大小的词汇表，这给后续的自回归模型在计算成本和参数大小方面带来了重大挑战。为了缓解这个问题，我们遵循了近期在视频量化和生成方面的工作（Yu et al. 2023; Wang et al. 2025），并将 $k$ 比特的编码分解到 $n$ 个子空间中。基于附录 H (Q3) 中详述的参数节省和延迟成本之间的权衡，我们设定 
$n=2$。我们将编码划分为一个粗粒度子词元 $b\_{t}^{c}$ 和一个细粒度子词元 $b\_{t}^{f}$ ，两者具有相同的比特长度 $k\_c = k\_f = k/2$ ，其中 $k=k\_c+k\_f$ 。最终的编码 $b\_t$ 是这两个子词元的拼接：
```math
b_{t} = \bigl[b_{t}^{c},\,b_{t}^{f}\bigr]，\left(b_{t}^{c}, b_{t}^{f} \in\{-1,1\}^{k/2}\right)
```
。这种分解将一个在 $2^k$ 大小的词汇表上的单次预测，转变为两次在 $2^{k/2}$ 条目上的顺序预测，从而大大降低了计算和参数复杂度。

为了在每个词元内强制实现从粗到细的结构，我们使用一个复合目标来训练分词器，该目标结合了层次化重构损失和 BSQ 的承诺损失（commitment loss）： 
```math
\mathcal{L}_{\text{tokenizer}}= \mathcal{L}_{\text{coarse}} + \mathcal{L}_{\text{fine}} + \lambda \mathcal{L}_{\text{quant}}, \quad (2)
```
其中 $\lambda$ 是一个平衡超参数。各组件定义如下：

-  $\mathcal{L}\_{\text{coarse}} = \mathbb{E}\bigl[\|\mathbf{x} - E_{\text{dec}}(\mathbf{b}^{c})\|^{2}\bigr]$ ，它训练粗粒度子词元 $\mathbf{b}^{c}$ 以形成低保真度的重构。
    
-  $\mathcal{L}\_{\text{fine}} = \mathbb{E}\bigl[\|\mathbf{x} - E_{\text{dec}}(\mathbf{b})\|^{2}\bigr]$ ，它评估使用完整词元 $\mathbf{b}$ 的高保真度重构。
    
-  $\mathcal{L}\_{\text{quant}}$ 是来自 BSQ 的量化损失（Zhao, Xiong, and Krähenbühl 2024），用于规范学习过程。它惩罚连续潜在向量 $\boldsymbol{\xi}$ 与其二元编码 $\mathbf{b}$, 之间的 L2 距离，使编码器的输出与学习到的码本对齐，以确保训练的稳定性。
    

这种层次化重构目标是我们设计的核心。通过优化 $\mathcal{L}\_{\text{coarse}}$，粗粒度子词元 $\mathbf{b}^{c}$ 学习捕捉输入的主要结构。因此，在优化 $\mathcal{L}\_{\text{fine}}$ 期间，细粒度子词元 $\mathbf{b}^f$ 被引导去编码完善粗略近似所需的残差信息。先前的工作表明，从粗到细的解码顺序可以提高生成质量（Wang et al. 2025）。我们的方法不是去识别那些固有包含粗略信息的词元并优先解码它们，而是在量化期间就被设计为将这种层次结构显式地强加到词元中。这确保了第一个子词元始终代表粗粒度信息，为后续的自回归建模阶段建立了期望的条件依赖关系。



### 层次化自回归建模

在分词阶段之后，得到的离散序列使用一个仅解码器的 Transformer（表示为 $E\_{\text{ar}}$ ）进行建模，该模型采用因果注意力（causal-attention）机制，以确保每个时间步的预测仅依赖于历史上下文。主要目标是估计词元序列 $\mathbf{b} = \{b\_1, \dots, b\_T\}$ 上的联合分布。方程 1 的一个简化形式可以推导为：
```math
p(\mathbf{b}) = \prod_{t=1}^{T} p(b_t \mid \mathbf{b}_{\lt t}), \quad(3)
```
 其中 $\mathbf{b}\_{<t}$ 表示直到时间 $t-1$ 的所有先前词元。 鉴于我们的层次化词元设计，其中每个词元被构造为 $b\_t = [b_t^{c}, b_t^{f}]$，我们使用链式法则进一步分解这个条件概率，以显式地捕捉固有的从粗到细的依赖关系： 
 ```math
p(b_t | \mathbf{b}_{\lt t}) = p(b_t^{c} | \mathbf{b}_{\lt t}) \cdot p(b_t^{f} | \mathbf{b}_{\lt t}, b_t^{c}) \quad (4)
```
这种表述允许模型首先预测粗粒度子词元，该子词元作为脚手架，用于随后生成细粒度的残差子词元。因此，预训练目标简化为在这种层次分解下最大化观测序列的对数似然。

如图 2（右）所示，自回归过程首先为每个时间步构建一个统一的输入向量。具体来说，在时间 $i$，子词元 $b\_i^{c}$ 和 $b\_i^{f}$ 使用两个不同的嵌入层被独立地投影到向量表征中，分别产生表征 
$e\_c(b\_i^{c})$ 和 $e\_f(b\_i^{f})$。然后将这些嵌入拼接起来并通过线性投影，以产生一个融合的输入向量： 
```math
\mathbf{v}_i = W_{\text{fuse}}([e_c(b_i^{c}); e_f(b_i^{f})]) \quad (5)
```
其中 $[\cdot;\cdot]$ 表示拼接， $W\_{\text{fuse}}$ 是一个可学习的权重矩阵，负责将组合后的表征投影到模型的潜在空间中。

然后，融合输入的序列 $\{\mathbf{v}\_1, \dots, \mathbf{v}\_{t-1}\}$ 由 Transformer $E\_{\text{ar}}$ 处理，该 Transformer 输出上下文相关的隐藏状态。处理 $\mathbf{b}\_{< t}$ 后的最终隐藏状态（表示为 $\mathbf{h}\_t$）随后用于预测词元 $b\_t$。这个隐藏状态接着为下一步的粗粒度和细粒度子词元的自回归预测提供信息，从而使模型能够有效地捕捉数据中固有的多尺度时间依赖关系。

**粗粒度子词元预测。** 历史向量 $\mathbf{h}_t$ 由一个线性头 $W\_c$ 投影，以产生第一个子词元分布的 logits： 
```math
p(b_{t}^{c} | \mathbf{b}_{< t}) = \text{softmax}(W_c \mathbf{h}_t) \quad (6)
```
**细粒度子词元预测。** 为了在方程 (4) 中建模条件依赖关系，上下文需要用预测的粗粒度子词元 $\widehat{b}_{t}^{c}$ 来更新。在训练期间，我们使用模型在上一步的自有预 $\widehat{b}\_{t}^{c}$ ，它是从预测分布 $p(b\_{t}^{c} | \mathbf{b}{< t})$ 中采样得到的，而不是使用真实的子词元（即 teacher-forcing）。我们发现这种采样策略通过减轻暴露偏差（exposure bias）来增强模型的鲁棒性，使训练分布与多步推理的自回归特性（即无法获取真实词元）更好地对齐。我们使用一个交叉注意力（cross-attention）机制，其中 $\widehat{b}\_{t}^{c}$ 的嵌入充当查询（query），而历史 $\mathbf{h}\_t$ 提供键（key）和值（value）。结果由第二个头 $W_f$ 投影：
```math
\mathbf{h}^{\text{update}}_t = \text{CrossAttn}(q=e_c(\widehat{b}_{t}^{c}), k=v=\mathbf{h}_t) \\ p(b_{t}^{f} | \mathbf{b}_{\lt t}, b_{t}^{c}) = \text{softmax}(W_f \mathbf{h}^{\text{update}}_t) \kern{1cm} (7)
```
总的训练目标 $\mathcal{L}\_{\text{ar}}$ 是数据的负对数似然，对两个预测步骤求和：
```math
\mathcal{L}_{\text{ar}} = - \mathbb{E}_{\mathbf{b} \sim \mathcal{D}} \sum_{t=1}^{T} \left[ \log p(b_t^{c} | \mathbf{b}_{\lt t}) + \log p(b_t^{f} | \mathbf{b}_{\lt t}, b_t^{c}) \right] \quad (8)
```
其中 $\mathcal{D}$ 代表数据分布。

### 模型预训练

**数据集** 为了确保预训练的质量，我们从头开始构建了一个大规模、高质量的金融 K 线数据集。与通用时间序列的基础模型研究（其中有精心策划的公共数据集可供使用）不同，全面、高质量的金融数据仍然有限。我们的数据集跨越超过 120 亿条观测值，涵盖 7 种采样频率，包含了来自 45 个全球交易所的广泛资产类别。为了保证数据质量，我们开发了一个针对金融 K 线数据独特特性量身定制的、精简的数据清洗流程，该流程能识别并过滤掉低质量的数据段，例如那些具有异常价格尖峰或长时间不活跃的时期。关于清洗流程的更多细节见附录 B。

**模型训练** 借鉴于 LLM 中观察到的规模法则（scaling laws）（Kaplan et al. 2020），我们训练了三个参数量递增的 Kronos 变体，最高接近 5 亿参数，以在性能和推理预算之间提供权衡。详细的模型配置见表 1。考虑到资源限制和实际部署场景，我们将最大上下文长度限制为 512 个词元。尽管如此，通过利用不同频率的 K 线数据，该设计仍然完全兼容任意的预测视野；例如，使用 1 分钟数据进行短期预测，使用日线数据进行周度或月度预测。完整的训练细节在附录 C 中提供。

---

**表 1：Kronos 家族的模型配置。** 我们详细列出了 Transformer 层数、模型维度 (dmodel​)、前馈网络维度 (dff​)、注意力头数、词汇表大小（2k）以及总参数量。

|  | 层数 | dmodel​ | dff​ | 头数 | 词汇表 (2k) | 参数量 |
| --- | --- | --- | --- | --- | --- | --- |
| Kronos$_{small}$ | 8 | 512 | 1024 | 8 | 20 | 24.7M |
| Kronos$_{base}$ | 12 | 832 | 2048 | 16 | 20 | 102.3M |
| Kronos$_{large}$ | 18 | 1664 | 3072 | 32 | 20 | 499.2M |

---

**推理** 在推理时，我们以自回归方式生成未来的词元序列，类似于文本生成。这个过程的随机性通过标准技术如温度缩放（temperature scaling）和 top-$p$（nucleus）采样（Holtzman et al. 2019）来控制。从 logits $\mathbf{z}$  中采样词元 $i$ 的概率由 $p\_i \propto \exp(z\_i / T)$ 给出，其中 $T$ 是温度。对于需要高精度的任务，可以通过生成多个未来轨迹（即蒙特卡洛（Monte Carlo）推演）并对解码后的连续值进行平均，来产生更稳定的预测，从而提高预测准确性。正如我们的实验所示，这种方法一致地提高了预测质量。

## 4 实验

为了全面评估 Kronos 作为金融 K 线数据基础模型的能力，我们设计了一套涵盖 5 个代表性任务的实验。这些任务被选中用以评估 Kronos 在预测性和生成性应用中的表现，从而展示其在实际量化金融场景中的多功能性。

### 实验设置

实验任务涵盖了预测性应用（价格序列、收益率和已实现波动率预测）、生成能力（合成 K 线生成），以及一个投资模拟，以评估实际适用性。

为了进行严格的比较，我们将 Kronos 与一个包含 25 个基线模型的综合套件进行了基准测试。这些基线模型是精心挑选的，代表了四种不同范式的 SOTA 水平：非预训练的全样本（full-shot）模型（例如 iTransformer (Liu et al. 2023)）、零样本（zero-shot）时间序列基础模型（例如 TimeMOE (Xiaoming et al. 2025)）、计量经济学波动率模型（例如 GARCH (Bollerslev 1986)，来自计量经济学的经典波动率预测方法），以及生成式时间序列模型（例如 DiffusionTS (Yuan and Qiao 2024)）。任务细节和基线模型在附录 D 中。我们的主要实验结果概览见图 4，完整的结果分解在附录 F 中。

![3e32abd55adccbfb8cd304cdf5d70d9d.png](en-resource://database/46299:0)

[图例] Kronos 全样本时间序列模型 零样本时间序列模型 计量经济学波动率模型 生成式时间序列模型

**图 4：五个代表性金融任务的主要实验结果。** 子图 (a-c) 显示了在价格序列、收益率和已实现波动率上的预测性能。子图 (d) 显示了生成模型在保真度和有用性方面的性能。子图 (e) 展示了投资模拟的回测结果。

**(a) 价格序列预测** **(b) 收益率预测** **(c) 已实现波动率预测** **(d) 合成 K 线生成** **(e) 投资模拟**

---

### 主要结果

**预测任务** 图 4(a-c) 展示了三个预测任务的结果。Kronos 在所有这些任务上都取得了一致的 SOTA 性能。特别地，对于价格序列预测，Kronos 在 RankIC 上相比最强的 TSFM 基线实现了惊人的 93% 提升，相比最佳的非预训练模型实现了 87% 的增益。此外，随着模型规模的扩大，在这些任务上的性能也持续提高，经验性地验证了时间序列基础模型的规模法则（Yao et al. 2024）。

**生成任务** 遵循既定实践（Yoon, Jarrett, and Van der Schaar 2019），我们从三个角度评估合成数据的质量： $\textit{多样性}$ 、$\textit{保真度}$ 和 $\textit{有用性}$ 。

为了评估$\textit{多样性}$——即生成样本覆盖真实数据分布的程度——我们使用了两种可视化方法：使用 t-SNE 将原始数据和合成数据投影到 2D 空间，以及通过核密度估计（KDE）比较它们的分布。如图 5 和附录 F 所示，t-SNE 图显示 Kronos 的合成数据更好地覆盖了原始数据空间，KDE 图也证实了其分布具有更高的相似性。

![4dd9683c95b3ca0d9c3d89c96d5a960b.png](en-resource://database/46301:0)


**图 5：上海证券交易所 15 分钟频率数据集上生成模型的视觉比较。** 顶行：原始数据（红色）与合成数据（蓝色）的 t-SNE 嵌入。底行：原始数据与合成数据的核密度估计（KDE）。

---

对于定量评估，我们使用判别分数（discriminative score）来评估 $\textit{保真度}$ （即数据真实性），该分数衡量分类器区分原始样本和合成样本的难度。我们还通过“在合成数据上训练，在真实数据上测试”（Train-on-Synthetic, Test-on-Real, TSTR）协议来评估 $\textit{有用性}$ （即合成数据用于训练下游模型的有效性），即在合成数据上训练一个预测模型，并在由真实数据组成的测试集上评估其 IC 和 RankIC。如图 4(d) 所示，Kronos 在 $\textit{保真度}$ 和 $\textit{有用性}$ 上均取得了最佳性能。随着模型规模的扩大，这种优势也得到了增强。

**投资模拟** 为了在真实的投资场景中验证 Kronos 的性能，我们在中国 A 股市场上模拟了一个仅做多（long-only）的投资策略，通过构建由每个模型的预测信号排名的前 $k$ 支股票组成的投资组合。如图 4(e) 所示，Kronos 的表现优于所有其他基线，实现了最高的年化超额收益（AER）和信息比率（IR）。这表明该模型可以有效地将其卓越的预测准确性转化为切实的投资收益。

### 消融研究

我们进行了消融研究，以验证我们的核心设计选择，重点关注两个问题：(Q1) 我们的建模范式与其他替代方案相比的有效性，以及 (Q2) 词汇表大小的影响。附录 E 中提供了关于分词器的额外消融研究。

**建模范式分析。** 为了解决 Q1，我们将 Kronos 与在预测空间和目标上有所不同、但参数量相当的变体进行了比较（表 2）。这些架构变体的详细描述在附录 D 中提供。我们测试了两个连续空间模型：$\textit{Direct-AR}$（使用 MSE 的标准回归基线）和 $\textit{Prob-AR}$ 。遵循既有工作（Yao et al. 2024），$\textit{Prob-AR}$ 使用Student-t 混合分布（Student-t mixture distribution）以更好地建模重尾数据分布。结果显示，我们的离散空间模型明显优于这些连续空间替代方案。我们还发现， $
\textit{Kronos-Parallel}$ （一个并发预测子词元的变体）的表现不如我们的顺序方法，这证明了建模子词元依赖关系的重要性。这些发现验证了我们的离散、顺序建模框架是该领域更有效的方法。

---
![b0a23321466ec07b7f0083876edaba7f.png](en-resource://database/46305:0)

**表 2：解剖 Kronos 架构选择的消融研究。** 我们将我们的模型与针对不同预测空间（连续 vs. 离散）和相应训练目标的变体进行比较。$\textit{Direct-AR}$ 作为标准回归基线。$\textit{Prob-AR}$ 评估了连续空间中概率建模的益处。$\textit{Kronos-Parallel}$ 对我们的顺序子词元设计进行了消融，它并发地预测子词元。最佳结果已加粗。


---

**词汇表大小的影响。** 为了回答 Q2，我们研究了词汇表大小如何影响模型性能。如图 6 所示，增加词汇表大小可以提高重构质量和预测准确性。更大的词汇表提供了更细粒度的表征，减少了量化误差。至关重要的是，这种增强的表征精度转化为了更好的预测结果。这一发现与视频生成领域的观察结果一致，即对于 LFQ 和 BSQ 等量化技术，更大的词汇表已被证明能带来更好的生成质量（Zhao, Xiong, and Krähenbühl 2024; Yu et al. 2023）。

---

![09db70e3cb8d9b7f5d3a702169bd34b3.png](en-resource://database/46307:0)

**图 6：词汇表大小对模型性能的影响。** 我们绘制了随着词汇表大小（2k）增加，重构质量和下游预测性能的变化。

---

### 测试时扩展（Test-Time Scaling）

我们的概率性、生成式框架的一个显著优势是，能够在推理时提高预测准确性，而无需重新训练模型。通过利用随机采样，Kronos 可以从相同的上下文中生成多个不同的未来轨迹。我们研究了通过对来自越来越多采样路径的结果进行平均来集成（ensembling）这些预测的效果。

图 7 展示了预测任务上的性能随采样数量变化的函数。结果表明，随着更多样本被纳入集成，IC 和 RankIC 均表现出一致的改善。对多个路径进行平均可以减轻生成过程中固有的随机性，并减少预测方差，从而产生更鲁棒和稳定的估计。这种能力提供了一种权衡，允许实践者在推理时的计算成本和期望的预测准确性水平之间进行平衡。

---
![af796cb07464d7f2444a132058fd385a.png](en-resource://database/46309:0)

**图 7：推理样本数量 (N) 对预测性能的影响。** 线条代表了 5 次不同随机种子运行的平均性能，阴影区域表示标准差。

---

## 5 结论

在这项工作中，我们介绍了 Kronos，一个专为金融 K 线序列设计的基础模型。Kronos 采用了一种新颖的两阶段框架，其中基于实例的分词器首先将连续的市场数据离散化为层次化的从粗到细的词元，然后由一个大型自回归 Transformer 对这些词元进行建模。全面的实证评估表明，Kronos 在价格序列预测以及合成 K 线生成和波动率预测等其他相关应用中树立了新的 SOTA 基准，显著优于现有的 TSFM 和其他基线。这些结果使 Kronos 成为一个强大且多功能的基础，适用于量化金融中的一系列应用。
